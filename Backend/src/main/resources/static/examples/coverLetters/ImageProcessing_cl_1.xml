<?xml version="1.0" encoding="UTF-8"?>
<coverLetter xmlns="http://ftn.uns.ac.rs/coverLetter"
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xsi:schemaLocation="http://ftn.uns.ac.rs/coverLetter file:/C:/Users/Nikola%20Zubic/Desktop/XMLWEB/sciXiv/Backend/src/main/resources/static/xmlSchemas/coverLetter.xsd" submissionDate="2006-05-04" id="id1">
    <publicationTitle>Image processing</publicationTitle>
    <version>1</version>
    <author>
        <name>Ziko Zikic</name>
        <educationTitle>Professor Emeritus GodFather</educationTitle>
        <affiliation>FTN</affiliation>
        <city>Novi Sad</city>
        <state>Serbia</state>
        <phoneNumber>003852185281785</phoneNumber>
        <email>ziko@gmail.com</email>
        <signature>ZGVmYXVsdA==</signature>
    </author>
    <targetPublisher>
        <editor>Mihajlo Kusljic</editor>
        <journal>Scientific NovoSadian</journal>
    </targetPublisher>
    <content>
        <paragraph>
            <boldText>Main motivation</boldText>
            <emphasizedText>We believe that the problem to progress in OMR for CWMN lies in the complexity involved in
                correctly modeling the composition of musical symbols. Unlike these hand-engineered multi-stage
                approaches, we propose a holistic strategy in which the musical notation is learned as a whole using
                machine learning strategies. However, to reduce the complexity to a feasible level, we do consider
                a first initial stage in which the image is pre-processed to find and separate the different staves of the
                score. Staves are good basic units to work on, analogously to similar text recognition where a single
                line of text is assumed as input unit. Note that this is not a strong assumption as there are successful
                algorithms for isolating staves, as mentioned above.
            </emphasizedText>
            <quote>
                <source>Muhammad Ali</source>
                <quoteContent>I hated every minute of training, but I said, 'Don't quit. Suffer now and live the rest of your life as a champion.'</quoteContent>
            </quote>
            <list ordered="false">
                <listItem>Medical imaging</listItem>
                <listItem>Military Computer Vision</listItem>
            </list>
            <boldText>Image sensors</boldText>
            <emphasizedText>Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell
                Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities,
                with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement.[3] 
                The purpose of early image processing was to improve the quality of the image. It was aimed for human beings to improve the visual effect of people. In 
                image processing, the input is a low-quality image, and the output is an image with improved quality. Common image processing include image enhancement, 
                restoration, encoding, and compression. The first successful application was the American Jet Propulsion Laboratory (JPL). They used image processing 
                techniques such as geometric correction, gradation transformation, noise removal, etc. on the thousands of lunar photos sent back by the Space Detector 
                Ranger 7 in 1964, taking into account the position of the sun and the environment of the moon. The impact of the successful mapping of the moon's surface
                map by the computer has been a huge success. Later, more complex image processing was performed on the nearly 100,000 photos sent back by the spacecraft,
                so that the topographic map, color map and panoramic mosaic of the moon were obtained, which achieved extraordinary results and laid a solid foundation
                for human landing on the moon.[4]
                
                The cost of processing was fairly high, however, with the computing equipment of that era. That changed in the 1970s, when digital image processing 
                proliferated as cheaper computers and dedicated hardware became available. This led to images being processed in real-time, for some dedicated problems 
                such as television standards conversion. As general-purpose computers became faster, they started to take over the role of dedicated hardware for all but 
                the most specialized and computer-intensive operations. With the fast computers and signal processors available in the 2000s, digital image processing 
                has become the most common form of image processing, and is generally used because it is not only the most versatile method, but also the cheapest.
                
            </emphasizedText>
        </paragraph>
        
        <paragraph>
            <boldText>Image compression</boldText>
            <emphasizedText>An important development in digital image compression technology was the discrete cosine transform (DCT), a lossy compression technique first 
                proposed by Nasir Ahmed in 1972.[14] DCT compression became the basis for JPEG, which was introduced by the Joint Photographic Experts Group in 1992.[15]
                JPEG compresses images down to much smaller file sizes, and has become the most widely used image file format on the Internet.[16] Its highly efficient 
                DCT compression algorithm was largely responsible for the wide proliferation of digital images and digital photos,[17] with several billion JPEG images 
                produced every day as of 2015.[18]
                
            </emphasizedText>

            <boldText>Medical imaging</boldText>
            <emphasizedText>In 1972, the engineer from British company EMI Housfield invented the X-ray computed tomography device for head diagnosis, 
                which is what we usually called CT(Computer Tomography). The CT nucleus method is based on the projection of the human head section and
                is processed by computer to reconstruct the cross-sectional image, which is called image reconstruction. In 1975, EMI successfully 
                developed a CT device for the whole body, which obtained a clear tomographic image of various parts of the human body. In 1979, this
                diagnostic technique won the Nobel Prize.[4] Digital image processing technology for medical applications was inducted into the Space
                Foundation Space Technology Hall of Fame in 1994.[24]
                
            </emphasizedText>

            <list ordered="true">
                <listItem>Simple IP</listItem>
                <listItem>Complex IP</listItem>
            </list>
            
        </paragraph>
    </content>
</coverLetter>
