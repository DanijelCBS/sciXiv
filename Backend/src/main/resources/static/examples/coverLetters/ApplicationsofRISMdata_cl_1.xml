<?xml version="1.0" encoding="UTF-8"?>
<cl:coverLetter xmlns:cl="http://ftn.uns.ac.rs/coverLetter">
    <cl:publicationTitle>Applications of RISM data</cl:publicationTitle>
    <cl:author>
        <cl:name>Keil, K.</cl:name>
        <cl:educationTitle>phD</cl:educationTitle>
        <cl:affiliation>Research Center</cl:affiliation>
        <cl:city>New York</cl:city>
        <cl:state>USA</cl:state>
        <cl:phoneNumber>884817851487</cl:phoneNumber>
        <cl:email>keil@gmail.com</cl:email>
        <cl:signature>ZGVmYXVsdA==</cl:signature>
    </cl:author>
    <cl:content>
        <cl:paragraph>
            <cl:boldText>We believe that the problem to progress in OMR for CWMN lies in the complexity involved in
                correctly modeling the composition of musical symbols. Unlike these hand-engineered multi-stage
                approaches, we propose a holistic strategy in which the musical notation is learned as a whole using
                machine learning strategies. However, to reduce the complexity to a feasible level, we do consider
                a first initial stage in which the image is pre-processed to find and separate the different staves of the
                score. Staves are good basic units to work on, analogously to similar text recognition where a single
                line of text is assumed as input unit. Note that this is not a strong assumption as there are successful
                algorithms for isolating staves, as mentioned above.</cl:boldText>
            <cl:emphasizedText>Then, the staff can be addressed as a single unit instead of considering it as a sequence of isolated
                elements that have to be detected and recognized independently. This also opens the possibility
                to boost the optical recognition by taking into account the musical context which, in spite of being
                extremely difficult to model entirely, can certainly help in the process. Thus, it seems interesting to
                tackle the OMR task over single staves in an holistic fashion, in which the expected output is directly
                the sequence of musical symbols present in the image.</cl:emphasizedText>
            <cl:quote>
                <cl:source>Kobe Bryant</cl:source>
                <cl:quoteContent>The most important thing is to try and inspire people so that they can be great in whatever they want to do.</cl:quoteContent>
            </cl:quote>
            <cl:list ordered="true">
                <cl:listItem>RISM</cl:listItem>
                <cl:listItem>Data Science</cl:listItem>
            </cl:list>
            <cl:boldText>Information about manuscripts and printed music indexed in RISM (Répertoire International des Sources Musicales), a large, international project that 
                records and describes musical sources, was for decades available solely through book publications, CD-ROMs, or subscription services. Recent initiatives to make 
                the data available on a wider scale have resulted in, most significantly, a freely accessible online database and the availability of its data as open data and 
                linked open data. Previously, the task of increasing the amount of data was primarily carried out by RISM national groups and the Zentralredaktion 
                (Central Office). The current opportunities available by linking to other freely accessible databases and importing data from other resources open new 
                perspectives and prospects.
            </cl:boldText>
            <cl:emphasizedText>This paper describes the RISM data and their applications for digital libraries and digital musicological projects. We discuss 
                the possibilities and challenges in making available a large and growing quantity of data and how the data have been utilized in external library and 
                musicological projects. Interactive functions in the RISM OPAC are planned for the future, as is closer collaboration with the projects that use RISM data. 
                Ultimately, RISM would like to arrange a “take and give” system in which the RISM data are used in external projects, enhanced by the project participants, 
                and then delivered back to the RISM Zentralredaktion.</cl:emphasizedText>
            <cl:quote>
                <cl:source>Steve Jobs</cl:source>
                <cl:quoteContent>Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the 
                    only way to do great work is to love what you do. If you haven't found it yet, keep looking. Don't settle. As with all matters of the heart, you'll know 
                    when you find it.
                </cl:quoteContent>
            </cl:quote>
            <cl:list ordered="true">
                <cl:listItem>Deep learning</cl:listItem>
                <cl:listItem>Music</cl:listItem>
            </cl:list>
        </cl:paragraph>
        <cl:paragraph>
            <cl:boldText>Evaluation of algorithm</cl:boldText>
            <cl:emphasizedText>... To evaluate their algorithm, two different data sets are used which both consist of monophonic music in modern notation, however one 
                is printed and one handwritten. Experiments on the first dataset which comprises incipts from the RISM data set [9] yield a symbol/pitch error rate of 1.5% 
                and a rhythm error rate of 2.0%. The total error for both properties to be correct is 2.8%. ...
            </cl:emphasizedText>
            <cl:quote>
                <cl:source>Maya Angelou</cl:source>
                <cl:quoteContent>My mission in life is not merely to survive, but to thrive; and to do so with some passion, some compassion, some humor, and some style.
                </cl:quoteContent>
            </cl:quote>
            <cl:list ordered="false">
                <cl:listItem>AI</cl:listItem>
                <cl:listItem>Neural Networks</cl:listItem>
            </cl:list>
            <cl:boldText>boldText3</cl:boldText>
            <cl:emphasizedText>... A direct approach for search within music collections is to use OMR technology to transform the documents into symbolic pieces of information, 
                over which classical content-based or symbolic retrieval methods can be used [87], [22], [104], [287], [157], [173], [1], [97]. The problem is that these 
                transformations require a more comprehensive understanding of the processed documents (see Sections VI-B3 and VI-B4 below). ...
            </cl:emphasizedText>
            <cl:quote>
                <cl:source>source3</cl:source>
                <cl:quoteContent>quoteContent3</cl:quoteContent>
            </cl:quote>
            <cl:list ordered="false">
                <cl:listItem>Beethoven</cl:listItem>
                <cl:listItem>Classical music</cl:listItem>
            </cl:list>
        </cl:paragraph>
    </cl:content>
</cl:coverLetter>
